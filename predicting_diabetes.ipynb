{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Diabetes\n",
    "\n",
    "### Background: \n",
    "Diabetes is one of the most common and most expensive chronic diseases worldwide. In 2004 it was estimated that in the US alone, approximately 5 million people unknowingly had the disease while another 13 million were aware of their diagnosis. \n",
    "\n",
    "### Problem Statement:  \n",
    "Early detection of the disease can help reduce the risk of serious life changing complications such as premature heart disease, stroke, blindness, limb amputations, and kidney failure.  Models that can help predict an individual with diabetes could be a useful tool to support a physicianâ€™s decision-making process when working with patients. It could also be leveraged to screen populations of patient data to identify patients most likely to have undiagnosed diabetes and intervene with further testing and monitoring. This can be framed as a binary classification problem to separate those who will vs. those who will not develop diabetes.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "> **Citation for the data:** The Pima Indian Diabetes Dataset used originally came from this paper:\n",
    "** Smith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261--265). IEEE Computer Society Press. Now available for download via Kaggle [here](https://www.kaggle.com/uciml/pima-indians-diabetes-database).\n",
    "\n",
    "* Note that because the dataset is hosted on Kaggle, it can be downloaded by generating an API token for your user id and installing the Kaggle-cli in your notebook environment. \n",
    "* For simplicity in this notebook, I downloaded and extracted the data on my local machine and then uploaded it into my notebook environment. The file 'diabetes.csv' is the unmodified extracted download file from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ec2-user ec2-user 23873 Aug  5 06:00 data/raw/diabetes.csv\r\n"
     ]
    }
   ],
   "source": [
    "# confirm that the file is accessible\n",
    "!ls -al data/raw/diabetes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the data into a dataframe\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "source_data_dir = 'data/raw'\n",
    "clean_data_dir = 'data/train-test'\n",
    "\n",
    "diabetes_df = pd.read_csv(os.path.join(source_data_dir, 'diabetes.csv'))\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion of missing variables:\n",
    "\n",
    "There are missing variable in the dataset although they're not all immediately apparent because they are coded as zeros rather than NaN or NA values. Because zero can be a valid measurement for some of the variables, we'll need to consider them one by one:\n",
    "\n",
    "**Pregnancies** - 0 can be a valid measurement\n",
    "\n",
    "**Glucose:** - 0 is unlikely to be a valid measurement\n",
    "\n",
    "**Blood PRessure:** - 0 is unlikely to be a valid measurement\n",
    "\n",
    "**Skin Thickness:** - 0 is unlikely to be a valid measurement\n",
    "\n",
    "**Insulin:** - 0 is unlikely to be a valid measurement\n",
    "\n",
    "**BMI:** - 0 is unlikely to be a valid measurement\n",
    "\n",
    "**DiabetesPedigreeFunction:** - 0 can be a valid measurement score representing hereditary risk of diabetes based on familial and closeness of genetic relationships. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of zero as value:\n",
      "\t Glucose: 5\n",
      "\t Blood Pressure: 35\n",
      "\t SkinThickness: 227\n",
      "\t Insulin: 374\n",
      "\t BMI: 11\n",
      "\t Glucose + BloodPressure + BMI all 0: 0\n"
     ]
    }
   ],
   "source": [
    "# look at missing values -- indicated with a zero\n",
    "\n",
    "print(\"Counts of zero as value:\")\n",
    "print(\"\\t Glucose: {}\".format(sum(diabetes_df.Glucose == 0)))\n",
    "print(\"\\t Blood Pressure: {}\".format(sum(diabetes_df.BloodPressure == 0)))\n",
    "print(\"\\t SkinThickness: {}\".format(sum(diabetes_df.SkinThickness == 0)))\n",
    "print(\"\\t Insulin: {}\".format(sum(diabetes_df.Insulin == 0)))\n",
    "print(\"\\t BMI: {}\".format(sum(diabetes_df.BMI == 0)))\n",
    "\n",
    "print(\"\\t Glucose + BloodPressure + BMI all 0: {}\".format(sum((diabetes_df.Glucose == 0) &\n",
    "                                                          (diabetes_df.BloodPressure == 0) &\n",
    "                                                          (diabetes_df.BMI == 0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My intention is to use tree based models to because they can offer more straightforward explainability than non-linear models and in a healthcare context that can be important to those using the output of the model. Linear models such as trees don't necesarily need to have normalized data values. Likewise they should be able to make cuts around the missing values indicated as zeros. Based on these factors, in my initial modeling, I'm not going to normalize the data or remove the missing values. Depending on model performance this is something I will revisit if needed, however in a real world situation, where some of these data elements will likely be missing at prediction time, having a model that is robust enough to make good predictions even in their absence would have a lot of value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (614, 8) Training label shape: (614,)\n",
      "Validation data shape: (77, 8) Validation label shape: (77,)\n",
      "Testing data shape: (77, 8) Testing label shape: (77,)\n"
     ]
    }
   ],
   "source": [
    "# preprocess data - wrap in a function in case add'l preprocessing steps are needed\n",
    "# to begin with, just splitting to train/test sets\n",
    "# hold out 1/4 of data for testing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "# rearrange to pass to train_test_split\n",
    "labels = diabetes_df.Outcome\n",
    "data = diabetes_df.drop(columns = ['Outcome'])\n",
    "    \n",
    "random_state = 27\n",
    "\n",
    "# split into train, valtest splits, putting 80% of data into training\n",
    "X_train, X_valtest, y_train, y_valtest = train_test_split(data, labels, \n",
    "                                                          random_state = random_state,\n",
    "                                                          test_size = .2)\n",
    "\n",
    "# split remaining 20% of data in valtest equally so 10% validation / 10% testing\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_valtest, y_valtest,\n",
    "                                                random_state = random_state,\n",
    "                                                test_size = .5)\n",
    "\n",
    "# print sizes to make sure we got what we expected\n",
    "print(\"Training data shape: {} Training label shape: {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Validation data shape: {} Validation label shape: {}\".format(X_val.shape, y_val.shape))\n",
    "print(\"Testing data shape: {} Testing label shape: {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure data for processing by training model and store as csv\n",
    "def make_csv(x, y, filename, data_dir):\n",
    "    '''Merges features and labels and converts them into one csv file with labels in the first column.\n",
    "       :param x: Data features\n",
    "       :param y: Data labels\n",
    "       :param file_name: Name of csv file, ex. 'train.csv'\n",
    "       :param data_dir: The directory where files will be saved\n",
    "       '''\n",
    "\n",
    "    # make data dir, if it does not exist\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    \n",
    "    df_X = pd.DataFrame(x)\n",
    "    df_y = pd.DataFrame(y)\n",
    "    \n",
    "    df_all = pd.concat([df_y,df_X], axis=1)\n",
    "    \n",
    "    df_all.to_csv(data_dir + '/' + filename, index = False, header=False)\n",
    "\n",
    "    # nothing is returned, but a print statement indicates that the function has run\n",
    "    print('Path created: '+str(data_dir)+'/'+str(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path created: data/train-test/train.csv\n",
      "Path created: data/train-test/validation.csv\n",
      "Path created: data/train-test/test.csv\n"
     ]
    }
   ],
   "source": [
    "make_csv(X_train, y_train, 'train.csv', clean_data_dir)\n",
    "make_csv(X_val, y_val, 'validation.csv', clean_data_dir)\n",
    "make_csv(X_test, y_test, 'test.csv', clean_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-501454055284/capstone\n"
     ]
    }
   ],
   "source": [
    "# copy data to s3\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "# session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create an S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "# set prefix, a descriptive name for a directory  \n",
    "prefix = 'capstone'\n",
    "\n",
    "# upload all data to S3\n",
    "input_data = sagemaker_session.upload_data(path=clean_data_dir, bucket=bucket, key_prefix=prefix)\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build xgBoost estimator\n",
    "# As stated above, we use this utility method to construct the image name for the training container.\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(sagemaker_session.boto_region_name, 'xgboost')\n",
    "\n",
    "# Now that we know which container to use, we can construct the estimator object.\n",
    "xgb = sagemaker.estimator.Estimator(container, # The image name of the training container\n",
    "                                    role,      # The IAM role to use (our current role in this case)\n",
    "                                    train_instance_count=1, # The number of instances to use for training\n",
    "                                    train_instance_type='ml.m4.xlarge', # The type of instance to use for training\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                                                        # Where to save the output (the model artifacts)\n",
    "                                    sagemaker_session=sagemaker_session) # The current SageMaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='reg:linear',\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-11 22:53:15 Starting - Starting the training job...\n",
      "2019-08-11 22:53:17 Starting - Launching requested ML instances......\n",
      "2019-08-11 22:54:19 Starting - Preparing the instances for training......\n",
      "2019-08-11 22:55:37 Downloading - Downloading input data\n",
      "2019-08-11 22:55:37 Training - Downloading the training image..\n",
      "\u001b[31mArguments: train\u001b[0m\n",
      "\u001b[31m[2019-08-11:22:55:56:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[31m[2019-08-11:22:55:56:INFO] File size need to be processed in the node: 0.02mb. Available memory size in the node: 8591.86mb\u001b[0m\n",
      "\u001b[31m[2019-08-11:22:55:56:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m[22:55:56] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[31m[22:55:56] 614x8 matrix with 4912 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[31m[2019-08-11:22:55:56:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m[22:55:56] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[31m[22:55:56] 77x8 matrix with 616 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 32 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[0]#011train-rmse:0.468668#011validation-rmse:0.473808\u001b[0m\n",
      "\u001b[31mMultiple eval metrics have been passed: 'validation-rmse' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[31mWill train until validation-rmse hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 30 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[1]#011train-rmse:0.447873#011validation-rmse:0.456281\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 32 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[2]#011train-rmse:0.429702#011validation-rmse:0.445308\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 38 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[3]#011train-rmse:0.421537#011validation-rmse:0.441713\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 34 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[4]#011train-rmse:0.415442#011validation-rmse:0.436961\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 34 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[5]#011train-rmse:0.409472#011validation-rmse:0.431263\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 24 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[6]#011train-rmse:0.405185#011validation-rmse:0.428576\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 34 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[7]#011train-rmse:0.404837#011validation-rmse:0.428188\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 32 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[8]#011train-rmse:0.404545#011validation-rmse:0.427849\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 34 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[9]#011train-rmse:0.404424#011validation-rmse:0.427703\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 28 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[10]#011train-rmse:0.400522#011validation-rmse:0.42458\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 44 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[11]#011train-rmse:0.400371#011validation-rmse:0.424392\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 30 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[12]#011train-rmse:0.397327#011validation-rmse:0.417691\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 36 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[13]#011train-rmse:0.397293#011validation-rmse:0.417652\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 34 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[14]#011train-rmse:0.397258#011validation-rmse:0.417608\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 40 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[15]#011train-rmse:0.397257#011validation-rmse:0.417608\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 44 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[16]#011train-rmse:0.397249#011validation-rmse:0.417596\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[17]#011train-rmse:0.397268#011validation-rmse:0.417622\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 34 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[18]#011train-rmse:0.397268#011validation-rmse:0.417622\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 30 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[19]#011train-rmse:0.397287#011validation-rmse:0.417645\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 34 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[20]#011train-rmse:0.397278#011validation-rmse:0.417634\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[21]#011train-rmse:0.39727#011validation-rmse:0.417624\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 28 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[22]#011train-rmse:0.397265#011validation-rmse:0.417618\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 34 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[23]#011train-rmse:0.39725#011validation-rmse:0.417598\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[24]#011train-rmse:0.39724#011validation-rmse:0.41758\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 36 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[25]#011train-rmse:0.397245#011validation-rmse:0.41759\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 40 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[26]#011train-rmse:0.397258#011validation-rmse:0.417609\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 34 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[27]#011train-rmse:0.397255#011validation-rmse:0.417604\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 40 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[28]#011train-rmse:0.397249#011validation-rmse:0.417596\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 32 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[29]#011train-rmse:0.39724#011validation-rmse:0.417574\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 36 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[30]#011train-rmse:0.397243#011validation-rmse:0.417586\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[31]#011train-rmse:0.397239#011validation-rmse:0.417577\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[32]#011train-rmse:0.39724#011validation-rmse:0.417579\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 42 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[33]#011train-rmse:0.397239#011validation-rmse:0.417575\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 36 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[34]#011train-rmse:0.397248#011validation-rmse:0.417594\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 40 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[35]#011train-rmse:0.397249#011validation-rmse:0.417595\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[36]#011train-rmse:0.397253#011validation-rmse:0.417602\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 44 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[37]#011train-rmse:0.397241#011validation-rmse:0.417581\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 44 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[38]#011train-rmse:0.397239#011validation-rmse:0.417576\u001b[0m\n",
      "\u001b[31m[22:55:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 30 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[39]#011train-rmse:0.397239#011validation-rmse:0.417577\u001b[0m\n",
      "\u001b[31mStopping. Best iteration:\u001b[0m\n",
      "\u001b[31m[29]#011train-rmse:0.39724#011validation-rmse:0.417574\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-08-11 22:56:08 Uploading - Uploading generated training model\n",
      "2019-08-11 22:56:08 Completed - Training job completed\n",
      "Billable seconds: 51\n"
     ]
    }
   ],
   "source": [
    "# This is a wrapper around the location of our train and validation data, to make sure that SageMaker\n",
    "# knows our data is in csv format.\n",
    "\n",
    "train_file_path = os.path.join(input_data, 'train.csv')\n",
    "s3_input_train = sagemaker.s3_input(s3_data=train_file_path, content_type='csv')\n",
    "\n",
    "val_file_path = os.path.join(input_data, 'validation.csv')\n",
    "s3_input_val = sagemaker.s3_input(s3_data=val_file_path, content_type='csv')\n",
    "\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------!CPU times: user 511 ms, sys: 25 ms, total: 537 ms\n",
      "Wall time: 8min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# deploy model for testing\n",
    "predictor = xgb.deploy(initial_instance_count=1,\n",
    "                      instance_type = 'ml.t2.medium')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct number of results returned.\n"
     ]
    }
   ],
   "source": [
    "# We need to tell the endpoint what format the data we are sending is in\n",
    "from sagemaker.predictor import csv_serializer\n",
    "import numpy as np\n",
    "predictor.content_type = 'text/csv'\n",
    "predictor.serializer = csv_serializer\n",
    "\n",
    "y_preds = predictor.predict(X_test.values).decode('utf-8')\n",
    "\n",
    "# predictions is currently a comma delimited string and so we would like to break it up\n",
    "# as a numpy array.\n",
    "y_preds = np.fromstring(y_preds, sep=',')\n",
    "\n",
    "# make sure the right number of labels are returned\n",
    "assert len(y_preds)==len(y_test), 'Unexpected number of predictions.'\n",
    "print('Correct number of results returned.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC_Score: 0.7045454545454545\n",
      "Accuracy Score: 0.7922077922077922\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_preds_new = [round(num) for num in y_preds.squeeze()]\n",
    "\n",
    "print(\"ROC_AUC_Score: {}\".format(roc_auc_score(y_test, y_preds_new)))\n",
    "print(\"Accuracy Score: {}\".format(accuracy_score(y_test, y_preds_new)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the DeleteEndpointConfig operation: Could not find endpoint configuration \"arn:aws:sagemaker:us-west-2:501454055284:endpoint-config/xgboost-2019-08-11-22-53-15-260\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-d81ae97868b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# clean up and summarize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mdelete_endpoint\u001b[0;34m(self, delete_endpoint_config)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \"\"\"\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdelete_endpoint_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delete_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36m_delete_endpoint_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_delete_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;34m\"\"\"Delete the Amazon SageMaker endpoint configuration\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_endpoint_config_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdelete_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelete_endpoint_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mdelete_endpoint_config\u001b[0;34m(self, endpoint_config_name)\u001b[0m\n\u001b[1;32m    971\u001b[0m         \"\"\"\n\u001b[1;32m    972\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Deleting endpoint configuration with name: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint_config_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEndpointConfigName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint_config_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdelete_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the DeleteEndpointConfig operation: Could not find endpoint configuration \"arn:aws:sagemaker:us-west-2:501454055284:endpoint-config/xgboost-2019-08-11-22-53-15-260\"."
     ]
    }
   ],
   "source": [
    "# clean up and summarize\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
