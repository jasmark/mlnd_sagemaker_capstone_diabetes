{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Diabetes\n",
    "\n",
    "## Background: \n",
    "Diabetes is one of the most common and most expensive chronic diseases worldwide. In 2004 it was estimated that in the US alone, approximately 5 million people unknowingly had the disease while another 13 million were aware of their diagnosis. \n",
    "\n",
    "## Problem Statement:  \n",
    "Early detection of the disease can help reduce the risk of serious life changing complications such as premature heart disease, stroke, blindness, limb amputations, and kidney failure.  Models that can help predict an individual with diabetes could be a useful tool to support a physicianâ€™s decision-making process when working with patients. It could also be leveraged to screen populations of patient data to identify patients most likely to have undiagnosed diabetes and intervene with further testing and monitoring. This can be framed as a binary classification problem to separate those who will vs. those who will not develop diabetes.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "> **Citation for the data:** The Pima Indian Diabetes Dataset used originally came from this paper:\n",
    "** Smith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261--265). IEEE Computer Society Press. Now available for download via Kaggle [here](https://www.kaggle.com/uciml/pima-indians-diabetes-database).\n",
    "\n",
    "* Note that because the dataset is hosted on Kaggle, it can be downloaded by generating an API token for your user id and installing the Kaggle-cli in your notebook environment. \n",
    "* For simplicity in this notebook, I downloaded and extracted the data on my local machine and then uploaded it into my notebook environment. The file 'diabetes.csv' is the unmodified extracted download file from Kaggle.\n",
    "\n",
    "# TODO: Discuss Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ec2-user ec2-user 23873 Aug  5 06:00 data/raw/diabetes.csv\r\n"
     ]
    }
   ],
   "source": [
    "# confirm that the file is accessible\n",
    "!ls -al data/raw/diabetes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data into a dataframe\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "source_data_dir = 'data/raw'\n",
    "clean_data_dir = 'data/train-test'\n",
    "\n",
    "diabetes_df = pd.read_csv(os.path.join(source_data_dir, 'diabetes.csv'))\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the data to get an idea of what it contains.\n",
    "diabetes_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual inspection of a summary of the data shows that there are a number of features with minimum values of 0. These are worth exploring in more detail. It does not look like the data contains any NaN / NA values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion of missing variables:\n",
    "\n",
    "There are missing variable in the dataset although they're not all immediately apparent because they are coded as zeros rather than NaN or NA values. Because zero can be a valid measurement for some of the variables, we'll need to consider them one by one:\n",
    "\n",
    "**Pregnancies** - 0 can be a valid measurement\n",
    "\n",
    "**Glucose:** - 0 is unlikely to be a valid measurement\n",
    "\n",
    "**Blood PRessure:** - 0 is unlikely to be a valid measurement\n",
    "\n",
    "**Skin Thickness:** - 0 is unlikely to be a valid measurement\n",
    "\n",
    "**Insulin:** - 0 is unlikely to be a valid measurement\n",
    "\n",
    "**BMI:** - 0 is unlikely to be a valid measurement\n",
    "\n",
    "**DiabetesPedigreeFunction:** - 0 can be a valid measurement score representing hereditary risk of diabetes based on familial and closeness of genetic relationships. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of zero as value:\n",
      "\t Glucose: 5\n",
      "\t Blood Pressure: 35\n",
      "\t SkinThickness: 227\n",
      "\t Insulin: 374\n",
      "\t BMI: 11\n",
      "\t Glucose + BloodPressure + BMI all 0: 0\n"
     ]
    }
   ],
   "source": [
    "# look at missing values -- indicated with a zero\n",
    "\n",
    "print(\"Counts of zero as value:\")\n",
    "print(\"\\t Glucose: {}\".format(sum(diabetes_df.Glucose == 0)))\n",
    "print(\"\\t Blood Pressure: {}\".format(sum(diabetes_df.BloodPressure == 0)))\n",
    "print(\"\\t SkinThickness: {}\".format(sum(diabetes_df.SkinThickness == 0)))\n",
    "print(\"\\t Insulin: {}\".format(sum(diabetes_df.Insulin == 0)))\n",
    "print(\"\\t BMI: {}\".format(sum(diabetes_df.BMI == 0)))\n",
    "\n",
    "print(\"\\t Glucose + BloodPressure + BMI all 0: {}\".format(sum((diabetes_df.Glucose == 0) &\n",
    "                                                          (diabetes_df.BloodPressure == 0) &\n",
    "                                                          (diabetes_df.BMI == 0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the data are on a variety of scales, it is worth scaling features. While a model like a decision tree should be able to work around the variation in scales, scaling the features gives a little more flexibility in choosing other model architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.743719</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500745</td>\n",
       "      <td>0.234415</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.427136</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.292929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396423</td>\n",
       "      <td>0.116567</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.919598</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347243</td>\n",
       "      <td>0.253629</td>\n",
       "      <td>0.183333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.447236</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.232323</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.418778</td>\n",
       "      <td>0.038002</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.688442</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.198582</td>\n",
       "      <td>0.642325</td>\n",
       "      <td>0.943638</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
       "0     0.352941  0.743719       0.590164       0.353535  0.000000  0.500745   \n",
       "1     0.058824  0.427136       0.540984       0.292929  0.000000  0.396423   \n",
       "2     0.470588  0.919598       0.524590       0.000000  0.000000  0.347243   \n",
       "3     0.058824  0.447236       0.540984       0.232323  0.111111  0.418778   \n",
       "4     0.000000  0.688442       0.327869       0.353535  0.198582  0.642325   \n",
       "\n",
       "   DiabetesPedigreeFunction       Age  \n",
       "0                  0.234415  0.483333  \n",
       "1                  0.116567  0.166667  \n",
       "2                  0.253629  0.183333  \n",
       "3                  0.038002  0.000000  \n",
       "4                  0.943638  0.200000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocesing - Feature Scaling\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "    \n",
    "# separate features from labels\n",
    "labels = diabetes_df.Outcome\n",
    "data = diabetes_df.drop(columns = ['Outcome'])\n",
    "\n",
    "# do basic Min/Max 0-1 scaling of features\n",
    "cols = data.columns\n",
    "scaler = MinMaxScaler()\n",
    "data = pd.DataFrame(scaler.fit_transform(X=data, y=None), columns=cols)\n",
    "\n",
    "# visually inspect to look for anything unexpected\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Validation/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (614, 8) Training label shape: (614,)\n",
      "Validation data shape: (77, 8) Validation label shape: (77,)\n",
      "Testing data shape: (77, 8) Testing label shape: (77,)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing - Train/Validation/Test Splits\n",
    "\n",
    "random_state = 27\n",
    "\n",
    "# split into train, valtest splits, putting 80% of data into training\n",
    "X_train, X_valtest, y_train, y_valtest = train_test_split(data, labels, \n",
    "                                                          random_state = random_state,\n",
    "                                                          test_size = .2)\n",
    "\n",
    "# split remaining 20% of data in valtest equally so 10% validation / 10% testing\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_valtest, y_valtest,\n",
    "                                                random_state = random_state,\n",
    "                                                test_size = .5)\n",
    "\n",
    "# print sizes to make sure we got what we expected\n",
    "print(\"Training data shape: {} Training label shape: {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Validation data shape: {} Validation label shape: {}\".format(X_val.shape, y_val.shape))\n",
    "print(\"Testing data shape: {} Testing label shape: {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure data for processing by training model and store as csv\n",
    "def make_csv(x, y, filename, data_dir):\n",
    "    '''Merges features and labels and converts them into one csv file with labels in the first column.\n",
    "       :param x: Data features\n",
    "       :param y: Data labels\n",
    "       :param file_name: Name of csv file, ex. 'train.csv'\n",
    "       :param data_dir: The directory where files will be saved\n",
    "       '''\n",
    "\n",
    "    # make data dir, if it does not exist\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    \n",
    "    df_X = pd.DataFrame(x)\n",
    "    df_y = pd.DataFrame(y)\n",
    "    \n",
    "    df_all = pd.concat([df_y,df_X], axis=1)\n",
    "    \n",
    "    df_all.to_csv(data_dir + '/' + filename, index = False, header=False)\n",
    "\n",
    "    # nothing is returned, but a print statement indicates that the function has run\n",
    "    print('Path created: '+str(data_dir)+'/'+str(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path created: data/train-test/train.csv\n",
      "Path created: data/train-test/validation.csv\n",
      "Path created: data/train-test/test.csv\n"
     ]
    }
   ],
   "source": [
    "make_csv(X_train, y_train, 'train.csv', clean_data_dir)\n",
    "make_csv(X_val, y_val, 'validation.csv', clean_data_dir)\n",
    "make_csv(X_test, y_test, 'test.csv', clean_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-501454055284/capstone\n"
     ]
    }
   ],
   "source": [
    "# copy data to s3\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "# session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create an S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "# set prefix, a descriptive name for a directory  \n",
    "prefix = 'capstone'\n",
    "\n",
    "# upload all data to S3\n",
    "input_data = sagemaker_session.upload_data(path=clean_data_dir, bucket=bucket, key_prefix=prefix)\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build & Train Model\n",
    "\n",
    "### Model Selection\n",
    "\n",
    "## TODO: xgboost, why, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build xgBoost estimator\n",
    "# As stated above, we use this utility method to construct the image name for the training container.\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(sagemaker_session.boto_region_name, 'xgboost')\n",
    "\n",
    "# Now that we know which container to use, we can construct the estimator object.\n",
    "xgb = sagemaker.estimator.Estimator(container, # The image name of the training container\n",
    "                                    role,      # The IAM role to use (our current role in this case)\n",
    "                                    train_instance_count=2, # The number of instances to use for training\n",
    "                                    train_instance_type='ml.m4.xlarge', # The type of instance to use for training\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                                                        # Where to save the output (the model artifacts)\n",
    "                                    sagemaker_session=sagemaker_session) # The current SageMaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='binary:logistic',\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "xgb_hyperparameter_tuner = HyperparameterTuner(estimator = xgb, # The estimator object to use as the basis for the training jobs.\n",
    "                                               objective_metric_name = 'validation:auc', # The metric used to compare trained models.\n",
    "                                               objective_type = 'Maximize', # Whether we wish to minimize or maximize the metric.\n",
    "                                               max_jobs = 10, # The total number of models to train\n",
    "                                               max_parallel_jobs = 5, # The number of models to train in parallel\n",
    "                                               hyperparameter_ranges = {\n",
    "                                                    'max_depth': IntegerParameter(3, 12),\n",
    "                                                    'eta'      : ContinuousParameter(0.05, 0.5),\n",
    "                                                    'min_child_weight': IntegerParameter(2, 8),\n",
    "                                                    'subsample': ContinuousParameter(0.5, 0.9),\n",
    "                                                    'gamma': ContinuousParameter(0, 10),\n",
    "                                               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "# This is a wrapper around the location of our train and validation data, to make sure that SageMaker\n",
    "# knows our data is in csv format.\n",
    "\n",
    "train_file_path = os.path.join(input_data, 'train.csv')\n",
    "s3_input_train = sagemaker.s3_input(s3_data=train_file_path, content_type='csv')\n",
    "\n",
    "val_file_path = os.path.join(input_data, 'validation.csv')\n",
    "s3_input_val = sagemaker.s3_input(s3_data=val_file_path, content_type='csv')\n",
    "\n",
    "#xgb.fit({'train': s3_input_train, 'validation': s3_input_val})\n",
    "xgb_hyperparameter_tuner.fit({'train': s3_input_train, 'validation': s3_input_val})\n",
    "xgb_hyperparameter_tuner.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Model for Testing\n",
    "\n",
    "Take the best performing model from the model search and deploy it as an endpoint for us to test against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-14 05:27:59 Starting - Preparing the instances for training\n",
      "2019-08-14 05:27:59 Downloading - Downloading input data\n",
      "2019-08-14 05:27:59 Training - Training image download completed. Training in progress.\n",
      "2019-08-14 05:27:59 Uploading - Uploading generated training model\n",
      "2019-08-14 05:27:59 Completed - Training job completed\u001b[31mArguments: train\u001b[0m\n",
      "\u001b[31m[2019-08-14:05:25:36:INFO] Running distributed xgboost training.\u001b[0m\n",
      "\u001b[31m[2019-08-14:05:25:40:INFO] Number of hosts: 2, master IP address: 10.0.224.236, host IP address: 10.0.224.236.\u001b[0m\n",
      "\u001b[31m[2019-08-14:05:25:40:INFO] Finished Yarn configuration files setup.\n",
      "\u001b[0m\n",
      "\u001b[32mArguments: train\u001b[0m\n",
      "\u001b[32m[2019-08-14:05:25:40:INFO] Running distributed xgboost training.\u001b[0m\n",
      "\u001b[32m[2019-08-14:05:25:40:INFO] Number of hosts: 2, master IP address: 10.0.224.236, host IP address: 10.0.212.135.\u001b[0m\n",
      "\u001b[32m[2019-08-14:05:25:40:INFO] Finished Yarn configuration files setup.\n",
      "\u001b[0m\n",
      "\u001b[32mstarting datanode, logging to /opt/amazon/hadoop/logs/hadoop--datanode-ip-10-0-212-135.us-west-2.compute.internal.out\u001b[0m\n",
      "\u001b[31mstarting namenode, logging to /opt/amazon/hadoop/logs/hadoop--namenode-ip-10-0-224-236.us-west-2.compute.internal.out\u001b[0m\n",
      "\u001b[32mstarting nodemanager, logging to /opt/amazon/hadoop/logs/yarn--nodemanager-ip-10-0-212-135.us-west-2.compute.internal.out\u001b[0m\n",
      "\u001b[32m[2019-08-14:05:25:45:INFO] File size need to be processed in the node: 0.05mb. Available memory size in the node: 8333.07mb\u001b[0m\n",
      "\u001b[31mstarting resourcemanager, logging to /opt/amazon/hadoop/logs/yarn--resourcemanager-ip-10-0-224-236.us-west-2.compute.internal.out\u001b[0m\n",
      "\u001b[31mstarting datanode, logging to /opt/amazon/hadoop/logs/hadoop--datanode-ip-10-0-224-236.us-west-2.compute.internal.out\u001b[0m\n",
      "\u001b[31mstarting nodemanager, logging to /opt/amazon/hadoop/logs/yarn--nodemanager-ip-10-0-224-236.us-west-2.compute.internal.out\u001b[0m\n",
      "\u001b[31m[2019-08-14:05:25:52:INFO] File size need to be processed in the node: 0.05mb. Available memory size in the node: 7857.8mb\u001b[0m\n",
      "\u001b[31m[2019-08-14:05:25:52:INFO] HTTP server started....\u001b[0m\n",
      "\u001b[31m[2019-08-14:05:25:52:INFO] Memory/core ratio is 7.83\u001b[0m\n",
      "\u001b[31m[2019-08-14:05:25:52:INFO] Yarn setup: number of workers: 2, physical cores per worker: 2, physical memory per worker: 15.67g.\u001b[0m\n",
      "\u001b[31m[2019-08-14:05:25:52:INFO] Yarn job submitted successfully.\u001b[0m\n",
      "\u001b[31m2019-08-14 05:25:52,928 INFO start listen on 10.0.224.236:9091\u001b[0m\n",
      "\u001b[31m/xgboost/dmlc-core/tracker/dmlc_tracker/yarn.py:37: UserWarning: cannot find \"/xgboost/dmlc-core/tracker/dmlc_tracker/../yarn/dmlc-yarn.jar\", I will try to run build\n",
      "  warnings.warn(\"cannot find \\\"%s\\\", I will try to run build\" % YARN_JAR_PATH)\u001b[0m\n",
      "\u001b[31msrc/main/java/org/apache/hadoop/yarn/dmlc/Client.java:37: warning: Signal is internal proprietary API and may be removed in a future release\u001b[0m\n",
      "\u001b[31mimport sun.misc.Signal;\n",
      "               ^\u001b[0m\n",
      "\u001b[31msrc/main/java/org/apache/hadoop/yarn/dmlc/Client.java:38: warning: SignalHandler is internal proprietary API and may be removed in a future release\u001b[0m\n",
      "\u001b[31mimport sun.misc.SignalHandler;\n",
      "               ^\u001b[0m\n",
      "\u001b[31msrc/main/java/org/apache/hadoop/yarn/dmlc/Client.java:276: warning: Signal is internal proprietary API and may be removed in a future release\n",
      "        Signal intSignal = new Signal(\"INT\");\n",
      "        ^\u001b[0m\n",
      "\u001b[31msrc/main/java/org/apache/hadoop/yarn/dmlc/Client.java:276: warning: Signal is internal proprietary API and may be removed in a future release\n",
      "        Signal intSignal = new Signal(\"INT\");\n",
      "                               ^\u001b[0m\n",
      "\u001b[31msrc/main/java/org/apache/hadoop/yarn/dmlc/Client.java:277: warning: Signal is internal proprietary API and may be removed in a future release\n",
      "        Signal.handle(intSignal, handler);\n",
      "        ^\u001b[0m\n",
      "\u001b[31msrc/main/java/org/apache/hadoop/yarn/dmlc/Client.java:332: warning: SignalHandler is internal proprietary API and may be removed in a future release\n",
      "    class CtrlCHandler implements SignalHandler{\n",
      "                                  ^\u001b[0m\n",
      "\u001b[31msrc/main/java/org/apache/hadoop/yarn/dmlc/Client.java:339: warning: Signal is internal proprietary API and may be removed in a future release\n",
      "        public void handle(Signal signal){\n",
      "                           ^\u001b[0m\n",
      "\u001b[31mNote: src/main/java/org/apache/hadoop/yarn/dmlc/ApplicationMaster.java uses unchecked or unsafe operations.\u001b[0m\n",
      "\u001b[31mNote: Recompile with -Xlint:unchecked for details.\u001b[0m\n",
      "\u001b[31m7 warnings\u001b[0m\n",
      "\u001b[31m19/08/14 05:25:57 INFO client.RMProxy: Connecting to ResourceManager at algo-1/10.0.224.236:8032\u001b[0m\n",
      "\u001b[31m19/08/14 05:25:57 INFO dmlc.Client: HDFS temp directory do not exist, creating.. /tmp\u001b[0m\n",
      "\u001b[31m19/08/14 05:25:59 INFO dmlc.Client: jobname=DMLC[nworker=2]:python,username=root\u001b[0m\n",
      "\u001b[31m19/08/14 05:25:59 INFO dmlc.Client: Submitting application application_1565760348266_0001\u001b[0m\n",
      "\u001b[31m19/08/14 05:25:59 INFO impl.YarnClientImpl: Submitted application application_1565760348266_0001\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:07,071 INFO @tracker All of 2 nodes getting started\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:07,280 INFO Multiple eval metrics have been passed: 'validation-auc' will be used for early stopping.\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:07,281 INFO [0]#011train-auc:0.807248#011validation-auc:0.77151\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:07,281 INFO Multiple eval metrics have been passed: 'validation-auc' will be used for early stopping.\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:07,281 INFO Will train until validation-auc hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:07,459 INFO [1]#011train-auc:0.83244#011validation-auc:0.80347\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:07,637 INFO [2]#011train-auc:0.839681#011validation-auc:0.807528\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:07,816 INFO [3]#011train-auc:0.854133#011validation-auc:0.82295\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:07,992 INFO [4]#011train-auc:0.864207#011validation-auc:0.807731\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:08,171 INFO [5]#011train-auc:0.865462#011validation-auc:0.827009\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:08,347 INFO [6]#011train-auc:0.864592#011validation-auc:0.825284\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:08,528 INFO [7]#011train-auc:0.870335#011validation-auc:0.82082\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:08,708 INFO [8]#011train-auc:0.871899#011validation-auc:0.829038\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:08,884 INFO [9]#011train-auc:0.875426#011validation-auc:0.833502\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:09,060 INFO [10]#011train-auc:0.878172#011validation-auc:0.835126\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:09,235 INFO [11]#011train-auc:0.881428#011validation-auc:0.83543\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:09,415 INFO [12]#011train-auc:0.882208#011validation-auc:0.836851\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:09,593 INFO [13]#011train-auc:0.882541#011validation-auc:0.832589\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:09,768 INFO [14]#011train-auc:0.884158#011validation-auc:0.834416\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:09,944 INFO [15]#011train-auc:0.884243#011validation-auc:0.83056\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:10,119 INFO [16]#011train-auc:0.884623#011validation-auc:0.828937\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:10,296 INFO [17]#011train-auc:0.8861#011validation-auc:0.822646\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:10,472 INFO [18]#011train-auc:0.887524#011validation-auc:0.821226\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:10,652 INFO [19]#011train-auc:0.887524#011validation-auc:0.821226\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:10,828 INFO [20]#011train-auc:0.888359#011validation-auc:0.814935\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:11,008 INFO [21]#011train-auc:0.888861#011validation-auc:0.820008\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:11,193 INFO [22]#011train-auc:0.889717#011validation-auc:0.813312\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:11,193 INFO Stopping. Best iteration:\u001b[0m\n",
      "\u001b[31m[12]#011train-auc:0.882208#011validation-auc:0.836851\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:11,194 INFO Finished training\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:11,195 INFO Finished training\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:11,196 INFO @tracker All nodes finishes job\u001b[0m\n",
      "\u001b[31m2019-08-14 05:26:11,196 INFO @tracker 4.12546205521 secs between node start and job finish\u001b[0m\n",
      "\u001b[32m[2019-08-14:05:27:48:INFO] Master host is not alive. Training might have finished. Shutting down.... Check the logs for algo-1 machine.\u001b[0m\n",
      "Billable seconds: 356\n",
      "----------------------------------------------------------------------------------------------------------------!CPU times: user 756 ms, sys: 37.2 ms, total: 793 ms\n",
      "Wall time: 9min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xgb_best_model = sagemaker.estimator.Estimator.attach(xgb_hyperparameter_tuner.best_training_job())\n",
    "# deploy model for testing\n",
    "predictor = xgb_best_model.deploy(initial_instance_count=1,\n",
    "                                  instance_type = 'ml.t2.medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at hyperparameters of best performing model. This is important for anyone who may want to reproduce these results without the need for searching for a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_tuning_objective_metric': 'validation:auc',\n",
       " 'early_stopping_rounds': '10',\n",
       " 'eta': '0.18715566233632602',\n",
       " 'gamma': '4.892529388133331',\n",
       " 'max_depth': '3',\n",
       " 'min_child_weight': '5',\n",
       " 'num_round': '500',\n",
       " 'objective': 'binary:logistic',\n",
       " 'subsample': '0.7196961595562865'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_best_model.hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict from the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct number of results returned.\n"
     ]
    }
   ],
   "source": [
    "# We need to tell the endpoint what format the data we are sending is in\n",
    "from sagemaker.predictor import csv_serializer\n",
    "import numpy as np\n",
    "predictor.content_type = 'text/csv'\n",
    "predictor.serializer = csv_serializer\n",
    "\n",
    "y_preds = predictor.predict(X_test.values).decode('utf-8')\n",
    "\n",
    "# predictions is currently a comma delimited string and so we would like to break it up\n",
    "# as a numpy array.\n",
    "y_preds = np.fromstring(y_preds, sep=',')\n",
    "\n",
    "# make sure the right number of labels are returned\n",
    "assert len(y_preds)==len(y_test), 'Unexpected number of predictions.'\n",
    "print('Correct number of results returned.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up and summarize\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance\n",
    "\n",
    "# TODO: Discuss metric selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.87        55\n",
      "           1       0.68      0.59      0.63        22\n",
      "\n",
      "   micro avg       0.81      0.81      0.81        77\n",
      "   macro avg       0.76      0.74      0.75        77\n",
      "weighted avg       0.80      0.81      0.80        77\n",
      "\n",
      "ROC_AUC_Score: 0.8768595041322315\n",
      "Accuracy Score: 0.8051948051948052\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_preds_ints = [round(num) for num in y_preds.squeeze()]\n",
    "\n",
    "print(classification_report(y_test, y_preds_ints, labels = [0,1]))\n",
    "print(\"ROC_AUC_Score: {}\".format(roc_auc_score(y_test, y_preds)))\n",
    "print(\"Accuracy Score: {}\".format(accuracy_score(y_test, y_preds_ints)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Discuss outcome"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
